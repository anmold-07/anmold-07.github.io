<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Digital Notebook</title><link href="https://anmold-07.github.io/" rel="alternate"></link><link href="https://anmold-07.github.io/feeds/all.atom.xml" rel="self"></link><id>https://anmold-07.github.io/</id><updated>2020-12-01T19:30:00-05:00</updated><entry><title>References for Probabilistic Graphical Models</title><link href="https://anmold-07.github.io/2020/09/01/graphical-models/" rel="alternate"></link><published>2020-09-01T10:25:00-04:00</published><updated>2020-12-01T19:30:00-05:00</updated><author><name>Anmol</name></author><id>tag:anmold-07.github.io,2020-09-01:/2020/09/01/graphical-models/</id><summary type="html">&lt;p&gt;References for a course on Probabilistic Graphical Models&lt;/p&gt;</summary><content type="html">
&lt;p&gt;In this post, I would briefly discuss the references that helped me understand important concepts in the broad field of Probabilistic Graphical Models. Given the sheer amount of topics that come under the umbrella of PGMs coupled with the fact that PGMs is an active area of research, one has to prioritize as to what topic one needs to focus on before diving deep in this course. &lt;/p&gt;
&lt;h3 id="beginner-level"&gt;Beginner level&lt;/h3&gt;
&lt;p&gt;If you are new to PGMs and have a decent background in probability theory, then I would highly recommend that you go through these](http://web.mit.edu/6.008/www/videos/index.html) videos first. These lectures also are part of the Computational Probability and Inference course on &lt;a href="https://www.edx.org/course/computational-probability-and-inference"&gt;edX&lt;/a&gt;. In my opinion, it sets the right motivation for why PGMs are useful and it was quite helpful to go through a few of these videos before officially diving deep in PGMs.&lt;/p&gt;
&lt;h3 id="intermediate-level-and-beyond"&gt;Intermediate level and Beyond&lt;/h3&gt;
&lt;p&gt;Nevertheless, from a research point of view, I found the following references very helpful:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://people.csail.mit.edu/dsontag/courses/pgm13/"&gt;This&lt;/a&gt; course taught by Dr. Sontag provides a rigorous holistic overview of PGMs.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.cse.iitd.ac.in/~parags/teaching/2015/au15/col776/"&gt;This&lt;/a&gt; course taught by Dr. Singla provides a good perspective on learning PGMs. It also has many additional references that are very helpful for applying the theory to many research problems.&lt;/p&gt;
&lt;p&gt;Two of the most comprehensive references for PGMs are &lt;a href="https://sailinglab.github.io/pgm-spring-2019/"&gt;this&lt;/a&gt; and &lt;a href="https://www.zabaras.com/probabilistic-graphical-models"&gt;this&lt;/a&gt; course taught by the Dr. Eric P. Xing and Dr. Zabaras, respectively. They cover a lot of material in a short span of time so it's important that you have some prior knowledge of machine learning in general. Each topic is covered in extreme detail and the video lectures/slides help understand the material better. In my opinion, it brings all of Machine learning together and after taking the course you realize that most of the specific machine learning models that are covered in standard ML courses are just very specific kinds of probabilistic graphical models. I felt that these two courses help builds the right perspective as an ML practitioner and therefore, the long videos are worth every second of your time.&lt;/p&gt;
&lt;p&gt;These &lt;a href="https://ermongroup.github.io/cs228-notes/"&gt;course notes&lt;/a&gt; by Stanford University are also a very handy reference. Finally, &lt;a href="https://www.coursera.org/specializations/probabilistic-graphical-models"&gt;this&lt;/a&gt; COURSERA specialization was also very helpful and serves to provide sound theoretical knowledge and also gives the opportunity to apply the inference and learning algorithms to various practical problems. Highly recommend the specialization.&lt;/p&gt;</content><category term="probability"></category><category term="randomness"></category><category term="decision theory"></category><category term="machine learning"></category><category term="graph theory"></category><category term="learning"></category><category term="inference"></category><category term="factorization"></category><category term="modeling"></category><category term="markov networks"></category><category term="bayesian networks"></category><category term="posterior probability"></category></entry><entry><title>References for Statistical Signal Processing</title><link href="https://anmold-07.github.io/2020/01/01/stat-signal-processing/" rel="alternate"></link><published>2020-01-01T10:25:00-05:00</published><updated>2020-05-01T19:30:00-04:00</updated><author><name>Anmol</name></author><id>tag:anmold-07.github.io,2020-01-01:/2020/01/01/stat-signal-processing/</id><summary type="html">&lt;p&gt;References for a course on Statistical Signal Processing&lt;/p&gt;</summary><content type="html">&lt;p&gt;This post will briefly summarize useful references on Statistical Signal Processing (SSP). Often, a course on Estimation and Detection Theory also covers similar topics and hence, in academia the names are most often used interchangeably. &lt;/p&gt;
&lt;h3 id="estimation-theory"&gt;Estimation Theory&lt;/h3&gt;
&lt;p&gt;A course on estimation theory usually covers the following topics:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sufficient statistics&lt;/li&gt;
&lt;li&gt;Minimum variance unbiased estimation&lt;/li&gt;
&lt;li&gt;Cramer-Rao lower bound&lt;/li&gt;
&lt;li&gt;Maximum likelihood and Bayesian estimation&lt;/li&gt;
&lt;li&gt;Wiener and Kalman filtering&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="detection-theory"&gt;Detection Theory&lt;/h3&gt;
&lt;p&gt;A course on detection theory usually covers the following topics:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Bayesian risk theory&lt;/li&gt;
&lt;li&gt;Neyman-Pearson detection&lt;/li&gt;
&lt;li&gt;Signal detection in Gaussian noise&lt;/li&gt;
&lt;li&gt;Bayes factors and GLRTs&lt;/li&gt;
&lt;li&gt;CFAR detection&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="references"&gt;References&lt;/h3&gt;
&lt;p&gt;Web-page for &lt;a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-432-stochastic-processes-detection-and-estimation-spring-2004/index.htm"&gt;this&lt;/a&gt; MIT OCW course was very helpful. 
To find the course notes accompanying the course, refer to this &lt;a href="https://www.rle.mit.edu/sia/wp-content/uploads/2015/04/chapter1.pdf"&gt;link&lt;/a&gt; and iterate through the chapters by modifying the URLs. I found these set of notes to be very comprehensive and meticulous.  &lt;/p&gt;
&lt;p&gt;&lt;a href="https://ocw.mit.edu/courses/mathematics/18-443-statistics-for-applications-fall-2003/lecture-notes/"&gt;This&lt;/a&gt; is another excellent reference with video lectures available on YouTube.
&lt;a href="https://web.eecs.umich.edu/~cscott/past_courses/eecs564w11/"&gt;This&lt;/a&gt; reference also covers a broad range of topics in depth.&lt;/p&gt;</content><category term="probability"></category><category term="randomness"></category><category term="decision theory"></category><category term="detection theory"></category><category term="estimation theory"></category><category term="signal processing"></category></entry><entry><title>References for Probability Theory and Applications</title><link href="https://anmold-07.github.io/2019/09/01/probab-theory/" rel="alternate"></link><published>2019-09-01T10:25:00-04:00</published><updated>2019-12-01T19:30:00-05:00</updated><author><name>Anmol</name></author><id>tag:anmold-07.github.io,2019-09-01:/2019/09/01/probab-theory/</id><summary type="html">&lt;p&gt;References for a course on Probability Theory and Applications&lt;/p&gt;</summary><content type="html">
&lt;p&gt;In this post, I would briefly summarize references that helped me in understanding fundamental concepts in the broad field of probability theory from an electrical engineers perspective. I hope these help you too!&lt;/p&gt;
&lt;h3 id="probability-theory"&gt;Probability Theory&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLbMVogVj5nJQqGHrpAloTec_lOKsG-foc"&gt;This playlist&lt;/a&gt; by Dr. Krishna Jagannathan from IIT Madras is an excellent reference for understanding the fundamental theory behind probability. This helped me become familiar with a lot sophisticated terms in literature especially various concepts related to Borel-Cantelli lemmas, convergence of a sequence of random variables etc. These are quite abstract concepts but explained beautifully in these lectures. The lecture notes accompanying this playlist can be found &lt;a href="http://www.ee.iitm.ac.in/~krishnaj/ee5110notes.htm"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A comprehensive reference for practice problems on probability theory can be found &lt;a href="https://courses.grainger.illinois.edu/ece313/fa2019/old_exams.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="stochastic-processes"&gt;Stochastic Processes&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://gtribello.github.io/mathNET/SOR3012.html"&gt;This course&lt;/a&gt; on Stochastic Processes is an excellent reference that focuses on both theoretical and practical aspects of advanced probability theory. It best explains continuous and discrete time &lt;a href="https://en.wikipedia.org/wiki/Markov_chain"&gt;Markov chains&lt;/a&gt; with numerous practical examples.&lt;/p&gt;
&lt;p&gt;No reference is complete without MIT OCW's courses. &lt;a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-262-discrete-stochastic-processes-spring-2011/index.htm"&gt;This course&lt;/a&gt; provides a comprehensive overview of discrete-time Stochastic Processes with very comprehensive lecture notes. References &lt;a href="http://math.mit.edu/~sheffield/fall2019math600.html"&gt;here&lt;/a&gt; were also helpful.&lt;/p&gt;
&lt;h3 id="time-series-analysis"&gt;Time Series Analysis&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLvOh309NvHlH0lVEyBFTv3oJ_TbDAWkP7"&gt;This playlist&lt;/a&gt; by Dr. Tangirala from IIT Madras is an excellent reference for time series-analysis. With the lectures notes open-sourced, this is the best series on time-series for both aspiring researchers and practitioners. The course also covers fundamental of estimation and detection theory in the last few lectures.&lt;/p&gt;</content><category term="probability"></category><category term="randomness"></category><category term="stochastic signals"></category></entry><entry><title>Integrating Latex with Pelican</title><link href="https://anmold-07.github.io/2018/12/04/second-post/" rel="alternate"></link><published>2018-12-04T10:25:00-05:00</published><updated>2018-12-04T19:30:00-05:00</updated><author><name>Anmol</name></author><id>tag:anmold-07.github.io,2018-12-04:/2018/12/04/second-post/</id><summary type="html">&lt;p&gt;Pelican with latex&lt;/p&gt;</summary><content type="html">&lt;p&gt;This post briefly discusses how to integrate &lt;a href="https://www.latex-project.org/"&gt;Latex&lt;/a&gt; with &lt;a href="https://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;. To integrate both, you would require a Pelican plugin called &lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/render_math"&gt;render_math&lt;/a&gt;. Follow the instructions in the link to set it up.&lt;/p&gt;</content><category term="math"></category><category term="latex"></category><category term="pelican"></category></entry><entry><title>Setting up this website</title><link href="https://anmold-07.github.io/2018/12/03/first-post/" rel="alternate"></link><published>2018-12-03T10:25:00-05:00</published><updated>2018-12-03T19:30:00-05:00</updated><author><name>Anmol</name></author><id>tag:anmold-07.github.io,2018-12-03:/2018/12/03/first-post/</id><summary type="html">&lt;p&gt;Setting up an Static Site Generator (SSG)&lt;/p&gt;</summary><content type="html">
&lt;h3 id="references-for-setting-up-this-static-site-generator"&gt;References for setting up this Static Site Generator&lt;/h3&gt;
&lt;p&gt;In this short post, I would like to give credit to a very well documented blog that helped me set up this website. In particular, &lt;a href="https://jackdewinter.github.io/2019/08/25/static-websites-setting-up-the-pelican-static-site-generator/"&gt;this&lt;/a&gt; well documented blog is a good reference on setting up a static site generator based on &lt;a href="https://blog.getpelican.com/"&gt;Pelican&lt;/a&gt;; Pelican is an open-source static site generator written in Python. Would highly encourage you to go through it in case you require to set up your own static website without spending too much time reading the documentation.&lt;/p&gt;</content><category term="pelican"></category><category term="publishing"></category><category term="blog"></category></entry></feed>