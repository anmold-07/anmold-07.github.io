<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Digital Notebook - Probabilistic Graphical Models</title><link href="https://anmold-07.github.io/" rel="alternate"></link><link href="https://anmold-07.github.io/feeds/probabilistic-graphical-models.atom.xml" rel="self"></link><id>https://anmold-07.github.io/</id><updated>2020-12-01T19:30:00-05:00</updated><entry><title>References for Probabilistic Graphical Models</title><link href="https://anmold-07.github.io/2020/09/01/my-super-post/" rel="alternate"></link><published>2020-09-01T10:25:00-04:00</published><updated>2020-12-01T19:30:00-05:00</updated><author><name>Anmol</name></author><id>tag:anmold-07.github.io,2020-09-01:/2020/09/01/my-super-post/</id><summary type="html">&lt;p&gt;References for a course on Probabilistic Graphical Models&lt;/p&gt;</summary><content type="html">&lt;p&gt;This course has many references on the internet. A lot also depends on what aspect of the course one would want to focus on and the motivation behind taking the course. If you are new to PGMs and have a decent background in probability theory, then I would highly recommend that you go through &lt;a href="http://web.mit.edu/6.008/www/videos/index.html"&gt;these&lt;/a&gt; videos first. These lectures also are part of the Computational Probability and Inference course on edX. It builds the right motivation for PGMs and it was helpful to go through a few videos before officially diving deep in PGMs.&lt;/p&gt;
&lt;p&gt;Nevertheless, from a research point of view, I found the following references very helpful:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://people.csail.mit.edu/dsontag/courses/pgm13/"&gt;This&lt;/a&gt; course taught by Dr. Sontag provides a rigorous holistic overview of PGMs.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.cse.iitd.ac.in/~parags/teaching/2015/au15/col776/"&gt;This&lt;/a&gt; course taught by Dr. Singla provides a good perspective on learning PGMs. It also has many additional references that are very helpful for applying the theory to many research problems.&lt;/p&gt;
&lt;p&gt;One of the most comprehensive reference for PGMs are &lt;a href="https://sailinglab.github.io/pgm-spring-2019/"&gt;this&lt;/a&gt; and &lt;a href="https://www.zabaras.com/probabilistic-graphical-models"&gt;this&lt;/a&gt; course taught by the Dr. Eric P. Xing and Dr. Zabaras respectively. They cover a lot of material in a short span of time so it's important that you have some prior knowledge of machine learning in general. Each topic is covered in extreme detail and the video lectures/slides help understand the material better. It brings all of Machine learning together that helps builds the right perspective in my opinion. These long videos are worth the time.&lt;/p&gt;
&lt;p&gt;These &lt;a href="https://ermongroup.github.io/cs228-notes/"&gt;course notes&lt;/a&gt; by Stanford University are also a very handy reference. Finally, &lt;a href="https://www.coursera.org/specializations/probabilistic-graphical-models"&gt;this&lt;/a&gt; COURSERA specialization is also very helpful and serves to provide sound theoretical knowledge and also gives the opportunity to apply the inference and learning algorithms to various practical problems. Highly recommend this course.  &lt;/p&gt;</content><category term="probability"></category><category term="randomness"></category><category term="decision theory"></category><category term="machine learning"></category><category term="graph theory"></category><category term="learning"></category><category term="inference"></category><category term="factorization"></category><category term="modeling"></category><category term="markov networks"></category><category term="bayesian networks"></category><category term="posterior probability"></category></entry></feed>